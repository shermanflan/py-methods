{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples Importing parquet files using Apache PyArrow\n",
    "- [Reference](azure-storage==0.37.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = os.environ['STORE_ACCOUNT_NAME']\n",
    "account_key = os.environ['STORE_ACCOUNT_KEY']\n",
    "container_name = os.environ['STORE_CONTAINER_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Single Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = 'patient_score_kinnser/2c3491d7-5d7f-44df-80cb-654035b4652e/part-00000.parquet'\n",
    "# parquet_file = 'patient_score_ltc400/0a094741-5a7d-4b42-9443-3802ebb0f582/part-00000.parquet'\n",
    "\n",
    "blob_service = BlobServiceClient(\n",
    "    account_url=f'https://{account_name}.blob.core.windows.net/',\n",
    "    credential=account_key)\n",
    "\n",
    "container_client = blob_service.get_container_client(container_name)\n",
    "\n",
    "blob_client = container_client.get_blob_client(\n",
    "    blob=parquet_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with BytesIO() as byte_stream:\n",
    "        storage_stream = blob_client.download_blob()\n",
    "        storage_stream.download_to_stream(byte_stream)\n",
    "        parquet_df = pq.read_table(source=byte_stream).to_pandas()\n",
    "except ResourceNotFoundError:\n",
    "    print(\"No blob found.\")\n",
    "\n",
    "# Alternate 1:\n",
    "#     with open('data/temp.parquet', \"wb\") as my_blob:\n",
    "#         storage_stream = blob_client.download_blob()\n",
    "#         my_blob.write(storage_stream.readall())\n",
    "#     with open('data/temp.parquet', \"rb\") as my_blob:\n",
    "#         parquet_df = pq.read_table(source=my_blob).to_pandas()\n",
    "\n",
    "parquet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with BytesIO() as byte_stream:\n",
    "        storage_stream = blob_client.download_blob()\n",
    "        storage_stream.download_to_stream(byte_stream)\n",
    "        parquet_file = pq.ParquetFile(byte_stream)\n",
    "        \n",
    "except ResourceNotFoundError:\n",
    "    print(\"No blob found.\")\n",
    "\n",
    "\n",
    "# parquet_file.schema\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Partitioned Parquet File\n",
    "- [Reference](http://arrow.apache.org/docs/python/parquet.html#reading-from-partitioned-datasets)\n",
    "- [Stack Overflow](https://stackoverflow.com/questions/58626126/partition-parquet-files-on-azure-blob-pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_service = BlobServiceClient(\n",
    "    account_url=f'https://{account_name}.blob.core.windows.net/',\n",
    "    credential=account_key)\n",
    "container_client = blob_service.get_container_client(container_name)\n",
    "\n",
    "blob_prefix = 'cc_crosswalk_kinnser/7d1fb957-c9e2-4500-bd5b-be57ae339c83'\n",
    "parquet_blobs = []\n",
    "\n",
    "for blob in container_client.list_blobs(name_starts_with=blob_prefix):\n",
    "    if blob.name.endswith('.parquet'):\n",
    "        print(f\"Found {blob.name}\")\n",
    "        parquet_blobs.append(blob.name)\n",
    "\n",
    "target_directory = f'data/cc_crosswalk_kinnser'\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "for blob in parquet_blobs:\n",
    "\n",
    "    file_name = os.path.split(blob)[1]\n",
    "    target_path = os.path.join(target_directory, file_name)\n",
    "\n",
    "    try:\n",
    "        print(f'Downloading {file_name} to {target_path}')\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        \n",
    "        with open(target_path, \"wb\") as f:\n",
    "            storage_stream = blob_client.download_blob()\n",
    "            storage_stream.download_to_stream(f)        \n",
    "        \n",
    "    except ResourceNotFoundError as e:\n",
    "        print(\"No blob found.\")\n",
    "\n",
    "dataset = pq.ParquetDataset(target_directory)\n",
    "table = dataset.read()\n",
    "\n",
    "cc_crosswalk_kinnser_df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_crosswalk_kinnser_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
